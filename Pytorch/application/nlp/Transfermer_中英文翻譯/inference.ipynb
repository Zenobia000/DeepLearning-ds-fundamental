{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d3e531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 36, 389, 270, 351, 494, 923]\n",
      "[7, 36, 389, 351, 494, 923]\n",
      "[23, 769, 807, 36, 36, 311]\n",
      "[7, 36, 389, 2330, 1285, 816]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "class Tokenizer:\n",
    "    def __init__(self, vocab_path, is_en=True):\n",
    "        with open(vocab_path,'rb') as f:\n",
    "            _, word2index, index2word = pickle.load(f)\n",
    "        if is_en: \n",
    "            word2index = {word: index + 1 for word, index in word2index.items()}\n",
    "            word2index.update({\"<PAD>\":0})\n",
    "            index2word = [\"<PAD>\"] + index2word\n",
    "        else:\n",
    "            word2index = {word: index + 3 for word, index in word2index.items()}\n",
    "            word2index.update({\"<PAD>\":0, \"<BOS>\": 1, \"<EOS>\":2})\n",
    "            index2word = [\"<PAD>\", \"<BOS>\", \"<EOS>\"] + index2word\n",
    "        self.word2index = word2index\n",
    "        self.index2word = index2word\n",
    "        self.PAD = 0\n",
    "        self.BOS = 1\n",
    "        self.EOS = 2\n",
    "    \n",
    "    def encode(self, sentence):\n",
    "        return [self.word2index[w] for w in sentence]\n",
    "    \n",
    "    def decode(self, indexes):\n",
    "        return [self.index2word[index] for index in indexes]\n",
    "\n",
    "    def length(self):\n",
    "        return len(self.index2word)\n",
    "    \n",
    "tokenizer_en = Tokenizer(vocab_path=\"./dataset/en.vec\", is_en=True)\n",
    "tokenizer_cn = Tokenizer(vocab_path=\"./dataset/ch.vec\", is_en=False)\n",
    "print(tokenizer_cn.encode(\"你好, 世界!\"))\n",
    "print(tokenizer_cn.encode(\"你好,世界!\"))\n",
    "print(tokenizer_cn.encode(\"這堂課好好玩\"))\n",
    "print(tokenizer_cn.encode(\"你好,黃志勝\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9432de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoder_embedding_num, encoder_hidden_num, en_vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(en_vocab_size, encoder_embedding_num)\n",
    "        self.rnn = nn.GRU(encoder_embedding_num, encoder_hidden_num, batch_first=True)\n",
    "        \n",
    "    def forward(self, en_index):\n",
    "        en_embedding = self.embedding(en_index)\n",
    "        encoder_output, encoder_hidden = self.rnn(en_embedding)\n",
    "        return encoder_output, encoder_hidden \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, decoder_embedding_num, decoder_hidden_num, cn_vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(cn_vocab_size, decoder_embedding_num)\n",
    "        self.rnn = nn.GRU(decoder_embedding_num, decoder_hidden_num, batch_first=True)\n",
    "        \n",
    "    def forward(self, decoder_input, hidden):\n",
    "        embedding = self.embedding(decoder_input)\n",
    "        decoder_output, dencoder_hidden = self.rnn(embedding, hidden)\n",
    "        return decoder_output, dencoder_hidden \n",
    "    \n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, decoder_state_t, encoder_outputs):\n",
    "        b,s,h=encoder_outputs.shape\n",
    "        attention_scores = torch.sum(\n",
    "            torch.tile(decoder_state_t.unsqueeze(dim=1), dims=(s,1)) * encoder_outputs\n",
    "            , dim=-1)\n",
    "        \n",
    "        attention_scores = torch.softmax(attention_scores, dim=-1)\n",
    "        context = torch.sum(attention_scores.unsqueeze(dim=-1) * encoder_outputs\n",
    "                           ,dim=1)\n",
    "        return context, attention_scores \n",
    "    \n",
    "    \n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 decoder_embedding_num, \n",
    "                 decoder_hidden_num, \n",
    "                 cn_vocab_size,\n",
    "                 drop_rate = 0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(cn_vocab_size, decoder_embedding_num)\n",
    "        self.gru = nn.GRUCell(decoder_embedding_num, decoder_hidden_num)\n",
    "        self.attention = AttentionBlock()\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "        \n",
    "    def forward(self, decoder_input, encoder_hidden, encoder_output):\n",
    "        embeded = self.embedding(decoder_input)\n",
    "        b,s,h = embeded.shape\n",
    "        ht = encoder_hidden[0]\n",
    "        decoder_output=[]\n",
    "        for t in range(s):\n",
    "            decoder_input = embeded[:,t,:]\n",
    "            ht = self.gru(decoder_input, ht)\n",
    "            context, attention_probs = self.attention(ht, encoder_output)\n",
    "            ht = self.dropout(ht)\n",
    "            yt = torch.cat((ht,context), dim=-1)\n",
    "            decoder_output.append(yt)\n",
    "        decoder_output = torch.stack(decoder_output,dim=0)\n",
    "        decoder_output = decoder_output.transpose(0,1)\n",
    "        return decoder_output      \n",
    "    \n",
    "class Seq2Seq_Model(nn.Module):\n",
    "    def __init__(self, \n",
    "               encoder_embedding_num, encoder_hidden_num, en_vocab_size,\n",
    "               decoder_embedding_num, decoder_hidden_num, cn_vocab_size,\n",
    "               project_size=3592,\n",
    "               dropout_rate=0.3):\n",
    "        super(Seq2Seq_Model, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(encoder_embedding_num, \n",
    "                               encoder_hidden_num, \n",
    "                               en_vocab_size)\n",
    "        self.decoder = AttentionDecoder(decoder_embedding_num, \n",
    "                                        decoder_hidden_num, \n",
    "                                        cn_vocab_size,\n",
    "                                        dropout_rate)\n",
    "        \n",
    "        self.project = nn.Linear(4*decoder_embedding_num, project_size)\n",
    "    def forward(self, en_index, cn_index):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(en_index)\n",
    "        decoder_outputs = self.decoder(cn_index, encoder_hidden, encoder_outputs)\n",
    "        ft = self.project(decoder_outputs)\n",
    "        return ft\n",
    "    \n",
    "    def inference(self, sentence, en_tokenizer, cn_tokenizer, max_length=50):\n",
    "        sentence = sentence.lower()\n",
    "        with torch.no_grad():\n",
    "            en_index = en_tokenizer.encode(sentence)\n",
    "            en_index = torch.tensor(en_index)\n",
    "            encoder_outputs, encoder_hidden = self.encoder(en_index)\n",
    "            decoder_inpit  = torch.tensor([[self.cn_tokenizer.BOS]])\n",
    "            ht = encoder_hidden[0]\n",
    "            predictions = []\n",
    "            for t in range(max_length):\n",
    "                embed = self.decoder.embedding(decoder_input)[:,0,:]\n",
    "                ht = self.decoder.gru(embed, ht)\n",
    "                context,_=self.decoder.attention(ht, encoder_output)\n",
    "                yt = torch.cat((ht, context), dim=-1)\n",
    "                pred = self.project(yt)\n",
    "                w_index = int(torch.argmax(pred, dim=-1))\n",
    "                word = self.cn_tokenizer.decode(w_index)\n",
    "                if word ==\"<EOS>\":\n",
    "                    break\n",
    "                predictions.append(word)\n",
    "                decoder_input =torch.tensor([[w_index]])\n",
    "            return \"\".join(predictions)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6212203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def inference(sentence, en_tokenizer, cn_tokenizer, max_length=50):\n",
    "    sentence = sentence.lower()\n",
    "    with torch.no_grad():\n",
    "        en_index = en_tokenizer.encode(sentence)\n",
    "        en_index = torch.tensor(en_index, device = device)\n",
    "        en_index = en_index.unsqueeze(0)  # 假設 batch_size=1，您可以根據實際情況調整 batch_size 的大小\n",
    "\n",
    "        encoder_output, encoder_hidden = model.encoder(en_index)\n",
    "        decoder_input  = torch.tensor([[cn_tokenizer.BOS]], device = device)\n",
    "        \n",
    "        ht = encoder_hidden[0]\n",
    "        predictions = []\n",
    "        for t in range(max_length):\n",
    "            embed = model.decoder.embedding(decoder_input)[:,0,:] \n",
    "            ht = model.decoder.gru(embed, ht)\n",
    "            context, _ = model.decoder.attention(ht, encoder_output)\n",
    "            yt = torch.cat((ht, context), dim=-1)\n",
    "            pred = model.project(yt)\n",
    "            w_index = int(torch.argmax(pred, dim=-1))\n",
    "            word = cn_tokenizer.decode([w_index])\n",
    "            if word ==\"<EOS>\":\n",
    "                break\n",
    "            predictions.append(word[0])\n",
    "            decoder_input = torch.tensor([[w_index]], device = device)\n",
    "#             print(word[0])\n",
    "    return \"\".join(predictions)\n",
    "    \n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "en_tokenizer = Tokenizer('./dataset/en.vec', is_en=True)\n",
    "cn_tokenizer = Tokenizer('./dataset/ch.vec', is_en=False)\n",
    "\n",
    "encoder_embedding_size = 128\n",
    "decoder_embedding_size = 128\n",
    "hidden_size = 256\n",
    "\n",
    "model = Seq2Seq_Model(encoder_embedding_size, hidden_size, en_tokenizer.length(),\n",
    "               decoder_embedding_size, hidden_size, cn_tokenizer.length(),\n",
    "               dropout_rate=0.1)\n",
    "\n",
    "model_weight = torch.load('model_seq2seq.pth', map_location=device)\n",
    "model.load_state_dict(model_weight.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7bfef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "輸入:How are you?\n",
      "輸出:你好嗎？<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "--------------------------------------------------\n",
      "輸入:I am fine\n",
      "輸出:我哪支来自行车吗？<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "--------------------------------------------------\n",
      "輸入:Check, please.\n",
      "輸出:請結帳。<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "--------------------------------------------------\n",
      "輸入:I love you.\n",
      "輸出:我爱你。<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "--------------------------------------------------\n",
      "輸入:She studied English in the morning.\n",
      "輸出:她上午學習英語。<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "--------------------------------------------------\n",
      "輸入:I'm pretty well.\n",
      "輸出:我很好。<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n"
     ]
    }
   ],
   "source": [
    "sentences=['How are you?',\n",
    "          'I am fine',\n",
    "          'Check, please.',\n",
    "          'I love you.',\n",
    "          'She studied English in the morning.',\n",
    "          'I\\'m pretty well.']\n",
    "\n",
    "model.eval()\n",
    "for sentence in sentences:\n",
    "    print('-'*50)\n",
    "    print('輸入:{}'.format(sentence))\n",
    "    predictions = inference(sentence, \n",
    "                  en_tokenizer, \n",
    "                  cn_tokenizer, \n",
    "                  max_length=30)\n",
    "    print('輸出:{}'.format(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8bea0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
