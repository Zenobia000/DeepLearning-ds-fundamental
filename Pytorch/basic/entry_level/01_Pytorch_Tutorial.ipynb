{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確認裝置類型 GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n",
      "Current GPU name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    \n",
    "    # Get the name of the current GPU\n",
    "    current_gpu_name = torch.cuda.get_device_name(0)  # Assuming you have at least one GPU\n",
    "    \n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    print(f\"Current GPU name: {current_gpu_name}\")\n",
    "       \n",
    "    # Now, operations will be performed on the GPU by default if available\n",
    "    cuda0 = torch.device('cuda:0')\n",
    "    tsr = torch.tensor([[1,2],[3,4],[5,6]], dtype=torch.float64, device=cuda0)\n",
    "else:\n",
    "    print(\"No GPU available. Using CPU.\")\n",
    "\n",
    "cuda0 = torch.device('cuda', 0)\n",
    "cuda1 = torch.device('cuda', 1)\n",
    "cpu = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor 創建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsr = torch.tensor([[1,2],[3,4],[5,6]]); tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "零矩陣:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "隨機矩陣:\n",
      "tensor([[0.5956, 0.8338, 0.2295],\n",
      "        [0.4152, 0.4992, 0.4502]])\n",
      "\n",
      "由數據構造的 Tensor:\n",
      "tensor([[1, 2, 5],\n",
      "        [3, 4, 7]])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# 創建一個 2x3 的零矩陣\n",
    "tensor1 = torch.zeros(2, 3)\n",
    "print(\"零矩陣:\")\n",
    "print(tensor1)\n",
    "\n",
    "# 創建一個 2x3 的隨機矩陣\n",
    "tensor2 = torch.rand(2, 3)\n",
    "print(\"\\n隨機矩陣:\")\n",
    "print(tensor2)\n",
    "\n",
    "# 創建一個直接由數據構造的 Tensor\n",
    "data = [[1, 2, 5], [3, 4, 7]]\n",
    "tensor3 = torch.tensor(data)\n",
    "print(\"\\n由數據構造的 Tensor:\")\n",
    "print(tensor3)\n",
    "print(tensor3.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsr = torch.tensor([[1,2],[3,4]], dtype=torch.float64); tsr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 邏輯運算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1881, -0.2218,  0.6883,  1.6405, -0.1076],\n",
       "        [-0.4914, -1.2082,  1.0859,  0.3926, -0.7073],\n",
       "        [-0.1189,  1.0979,  0.3442, -0.3480, -0.7166],\n",
       "        [-0.1212, -0.3576,  0.0276,  0.9781,  0.4469]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsr = torch.randn(4,5)\n",
    "tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6405)\n"
     ]
    }
   ],
   "source": [
    "# 1. max of entire tensor (torch.max(input) → Tensor)\n",
    "m = torch.max(tsr)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1881, 1.0979, 1.0859, 1.6405, 0.4469])\n",
      "tensor([0, 2, 1, 0, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2. max along a dimension (torch.max(input, dim, keepdim=False, *, out=None) → (Tensor, LongTensor))\n",
    "m, idx = torch.max(tsr,0)\n",
    "print(m)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1881, 1.0979, 1.0859, 1.6405, 0.4469])\n",
      "tensor([0, 2, 1, 0, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2-2\n",
    "m, idx = torch.max(input=tsr,dim=0)\n",
    "print(m)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1881, 1.0979, 1.0859, 1.6405, 0.4469])\n",
      "tensor([0, 2, 1, 0, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2-3\n",
    "m, idx = torch.max(tsr,0,False)\n",
    "print(m)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1881, 1.0979, 1.0859, 1.6405, 0.4469]])\n",
      "tensor([[0, 2, 1, 0, 3]])\n"
     ]
    }
   ],
   "source": [
    "# 2-4\n",
    "m, idx = torch.max(tsr,dim=0,keepdim=True)\n",
    "print(m)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1881, 1.0979, 1.0859, 1.6405, 0.4469])\n",
      "tensor([0, 2, 1, 0, 3])\n",
      "(tensor([1.1881, 1.0979, 1.0859, 1.6405, 0.4469]), tensor([0, 2, 1, 0, 3]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_20072\\4003094677.py:3: UserWarning: An output with one or more elements was resized since it had shape [1, 5], which does not match the required output shape [5]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ..\\aten\\src\\ATen\\native\\Resize.cpp:35.)\n",
      "  torch.max(tsr,0,False,out=p)\n"
     ]
    }
   ],
   "source": [
    "# 2-5\n",
    "p = (m,idx)\n",
    "torch.max(tsr,0,False,out=p)\n",
    "print(p[0])\n",
    "print(p[1])\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **tensor data type**\n",
    "![**tensor data type**](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*CHitOyDsG5fXhR80cAT3Ag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor <-----> numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy [[ 1.1881301  -0.22177304  0.688282    1.6404712  -0.10755035]\n",
      " [-0.49139878 -1.2082385   1.0859488   0.39258292 -0.7073044 ]\n",
      " [-0.11885507  1.0979258   0.344225   -0.34797606 -0.7166301 ]\n",
      " [-0.12120967 -0.3576219   0.02757552  0.97814554  0.4468925 ]]\n",
      "type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# tensor transfer to numpy\n",
    "tsr2numpy = tsr.numpy()\n",
    "print('numpy', tsr2numpy)\n",
    "print('type:', type(tsr2numpy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n",
      "dtype: torch.int32\n",
      "tensor: tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "dtype: torch.float32\n",
      "tensor: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n",
      "dtype: torch.int32\n",
      "tensor: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n",
      "dtype: torch.int32\n"
     ]
    }
   ],
   "source": [
    "# numpy transfer to tensor\n",
    "\n",
    "'''\n",
    "torch.Tensor\n",
    "torch.tensor\n",
    "torch.as_tensor\n",
    "torch.from_numpy\n",
    "\n",
    "'''\n",
    "arr = np.array([[1,2,3],[4,5,6]])\n",
    "\n",
    "#1 sol\n",
    "arr2tsr_1 = torch.tensor(arr)\n",
    "print(\"tensor:\", arr2tsr_1)\n",
    "print(\"dtype:\", arr2tsr_1.dtype)\n",
    "\n",
    "#2 sol\n",
    "arr2tsr_2 = torch.Tensor(arr)\n",
    "print(\"tensor:\", arr2tsr_2)\n",
    "print(\"dtype:\", arr2tsr_2.dtype)\n",
    "\n",
    "#3 sol\n",
    "arr2tsr_3 = torch.as_tensor(arr)\n",
    "print(\"tensor:\", arr2tsr_3)\n",
    "print(\"dtype:\", arr2tsr_3.dtype)\n",
    "\n",
    "#4 sol\n",
    "arr2tsr_4 = torch.from_numpy(arr)\n",
    "print(\"tensor:\", arr2tsr_4)\n",
    "print(\"dtype:\", arr2tsr_4.dtype)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor 運算操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5956, 0.8338, 0.2295],\n",
       "        [0.4152, 0.4992, 0.4502]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5],\n",
       "        [3, 4, 7]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor 加法結果:\n",
      "tensor([[1.5956, 2.8338, 5.2295],\n",
      "        [3.4152, 4.4992, 7.4502]])\n",
      "\n",
      "Tensor 乘法結果:\n",
      "tensor([[0.5956, 1.6675, 1.1477],\n",
      "        [1.2457, 1.9968, 3.1511]])\n",
      "\n",
      "重塑後的 Tensor:\n",
      "tensor([[1, 2, 5, 3, 4, 7]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor 加法\n",
    "result_add = tensor2 + tensor3\n",
    "print(\"\\nTensor 加法結果:\")\n",
    "print(result_add)\n",
    "\n",
    "\n",
    "# Tensor 加法 (apple 2 apple)\n",
    "result_muiltiple = tensor2 * tensor3\n",
    "print(\"\\nTensor 乘法結果:\")\n",
    "print(result_muiltiple)\n",
    "\n",
    "\n",
    "# Tensor 改變形狀\n",
    "reshaped = tensor3.view(1, 6)\n",
    "print(\"\\n重塑後的 Tensor:\")\n",
    "print(reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 參數追蹤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[-0.2016, -1.6679],\n",
      "        [ 0.2950, -1.2705],\n",
      "        [ 0.7401, -3.1303]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# auto_grad\n",
    "# 設定 requires_grad 指定參數是否追蹤\n",
    "\n",
    "# 指定tensor\n",
    "tsr = torch.tensor([[1,2],[3,4],[5,6]], dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "# 隨機tensor\n",
    "tsr_randn = torch.randn(3, 2, requires_grad=True)\n",
    "\n",
    "print(tsr)\n",
    "print(tsr_randn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_x tensor([[0.2396, 0.1117, 0.6634],\n",
      "        [0.1873, 0.3473, 0.3479]], requires_grad=True)\n",
      "tensor_y tensor([[0.4829, 0.7932, 0.1140],\n",
      "        [0.5022, 0.6296, 0.9223]], requires_grad=True)\n",
      "tensor_z tensor([[0.9059, 0.1766, 0.2995],\n",
      "        [0.5391, 0.3627, 0.2754]], requires_grad=True)\n",
      "----------------------------------------\n",
      "tensor([[0.4829, 0.7932, 0.1140],\n",
      "        [0.5022, 0.6296, 0.9223]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 建立隨機數值的 Tensor 並設定 requires_grad=True\n",
    "x = torch.rand(2,3, requires_grad=True)\n",
    "y = torch.rand(2,3, requires_grad=True)\n",
    "z = torch.rand(2,3, requires_grad=True)\n",
    "\n",
    "\n",
    "print(\"tensor_x\", x)\n",
    "print(\"tensor_y\", y)\n",
    "print(\"tensor_z\", z)\n",
    "\n",
    "\n",
    "print(\"--\" * 20)\n",
    "\n",
    "# 計算式子\n",
    "# b = x*y + z\n",
    "a = x * y\n",
    "b = a + z\n",
    "c = torch.sum(b)\n",
    "\n",
    "# 計算梯度\n",
    "c.backward()\n",
    "\n",
    "# 查看 x 的梯度值\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 停止梯度計算 \n",
    "5 大方法, 用在模型推論過程\n",
    "\n",
    "* detach()\n",
    "* with wotch.no_grad()\n",
    "* @torch.no_grad()\n",
    "* with torch.inference_mode()\n",
    "* @torch.inference_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6077,  0.3964,  1.4620], requires_grad=True)\n",
      "requires_grad True\n",
      "tensor([-0.6077,  0.3964,  1.4620])\n",
      "requires_grad False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "print(\"requires_grad\", x.requires_grad)\n",
    "\n",
    "# No gradient will be computed for y\n",
    "y = x.detach()\n",
    "print(y)\n",
    "print(\"requires_grad\", y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5487,  0.8920,  0.2638],\n",
      "        [-0.2611,  1.7792, -0.3887],\n",
      "        [ 1.5519,  1.4101,  0.1652]], requires_grad=True)\n",
      "requires_grad True\n",
      "tensor([[-3.0973,  1.7840,  0.5275],\n",
      "        [-0.5223,  3.5584, -0.7773],\n",
      "        [ 3.1038,  2.8201,  0.3304]])\n",
      "requires_grad False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(3, 3, requires_grad=True)\n",
    "print(x)\n",
    "print(\"requires_grad\", x.requires_grad)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "    print(y)\n",
    "\n",
    "print(\"requires_grad\", y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6129,  0.5429, -0.4001],\n",
      "        [ 0.2064,  0.3922, -0.1294],\n",
      "        [-0.5708,  1.1313,  0.2226]], requires_grad=True)\n",
      "requires_grad True\n",
      "tensor([[ 3.2258,  1.0857, -0.8003],\n",
      "        [ 0.4128,  0.7845, -0.2587],\n",
      "        [-1.1415,  2.2626,  0.4451]])\n",
      "requires_grad False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def double(x):\n",
    "    return x * 2\n",
    "\n",
    "x = torch.randn(3, 3, requires_grad=True)\n",
    "print(x)\n",
    "print(\"requires_grad\", x.requires_grad)\n",
    "\n",
    "y = double(x)\n",
    "print(y)\n",
    "\n",
    "print(\"requires_grad\", y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with torch.inference_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5451,  0.6024, -0.4503],\n",
      "        [ 1.7358, -1.6545,  1.5861],\n",
      "        [ 0.3672,  0.7445,  0.3024]], requires_grad=True)\n",
      "requires_grad True\n",
      "tensor([[ 1.0903,  1.2047, -0.9006],\n",
      "        [ 3.4717, -3.3089,  3.1721],\n",
      "        [ 0.7345,  1.4891,  0.6048]])\n",
      "requires_grad False\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3, requires_grad=True)\n",
    "print(x)\n",
    "print(\"requires_grad\", x.requires_grad)\n",
    "\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y = x * 2\n",
    "    print(y)\n",
    "print(\"requires_grad\", y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @torch.inference_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9562,  2.0713,  1.2839],\n",
      "        [-1.6120, -0.6295, -0.6977],\n",
      "        [-0.2354, -1.2650,  0.1786]], requires_grad=True)\n",
      "requires_grad True\n",
      "tensor([[ 3.9124,  4.1426,  2.5678],\n",
      "        [-3.2240, -1.2590, -1.3955],\n",
      "        [-0.4708, -2.5300,  0.3571]])\n",
      "requires_grad False\n"
     ]
    }
   ],
   "source": [
    "@torch.inference_mode()\n",
    "def double(x):\n",
    "    return x * 2\n",
    "\n",
    "x = torch.randn(3, 3, requires_grad=True)\n",
    "print(x)\n",
    "print(\"requires_grad\", x.requires_grad)\n",
    "\n",
    "\n",
    "y = double(x)\n",
    "print(y)\n",
    "print(\"requires_grad\", y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common errors**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code blocks show some common errors while using the torch library. First, execute the code with error, and then execute the next code block to fix the error. You need to change the runtime to GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\xdxd2\\Sunny_VS_worksapce\\Sunny_python\\lee hung yi\\ML2021-Spring\\Pytorch\\01_Pytorch_Tutorial.ipynb Cell 45\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 1. different device error\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y130sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mLinear(\u001b[39m5\u001b[39;49m,\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y130sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m])\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y130sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m y \u001b[39m=\u001b[39m model(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\cuda\\__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# 1. different device error\n",
    "# 5個神經元 hidden layer, 1個神經元 output\n",
    "model = torch.nn.Linear(5,1).to(\"cuda:0\")\n",
    "x = torch.Tensor([1,2,3,4,5]).to(\"cpu\")\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\xdxd2\\Sunny_VS_worksapce\\Sunny_python\\lee hung yi\\ML2021-Spring\\Pytorch\\01_Pytorch_Tutorial.ipynb Cell 46\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 1. different device error (fixed)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y131sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mTensor([\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m4\u001b[39;49m,\u001b[39m5\u001b[39;49m])\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y131sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y131sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\cuda\\__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# 1. different device error (fixed)\n",
    "x = torch.Tensor([1,2,3,4,5]).to(\"cuda:0\")\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\xdxd2\\Sunny_VS_worksapce\\Sunny_python\\lee hung yi\\ML2021-Spring\\Pytorch\\01_Pytorch_Tutorial.ipynb Cell 47\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y132sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y132sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m5\u001b[39m,\u001b[39m4\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y132sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m z \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39;49m y\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# 2. mismatched dimensions error\n",
    "x = torch.randn(4,5)\n",
    "y= torch.randn(5,4)\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# 2. mismatched dimensions error (fixed)\n",
    "y= y.transpose(0,1)\n",
    "z = x + y\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\xdxd2\\Sunny_VS_worksapce\\Sunny_python\\lee hung yi\\ML2021-Spring\\Pytorch\\01_Pytorch_Tutorial.ipynb Cell 49\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y134sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y134sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmodels\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y134sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m resnet18 \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49mresnet18()\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m# Neural Networks for Image Recognition\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y134sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m2048\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m244\u001b[39m,\u001b[39m244\u001b[39m) \u001b[39m# Create fake data (512 images)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y134sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m out \u001b[39m=\u001b[39m resnet18(data\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39m# Use Data as Input and Feed to Model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\cuda\\__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# 3. cuda out of memory error\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18().to(\"cuda:0\") # Neural Networks for Image Recognition\n",
    "data = torch.randn(2048,3,244,244) # Create fake data (512 images)\n",
    "out = resnet18(data.to(\"cuda:0\")) # Use Data as Input and Feed to Model\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\xdxd2\\Sunny_VS_worksapce\\Sunny_python\\lee hung yi\\ML2021-Spring\\Pytorch\\01_Pytorch_Tutorial.ipynb Cell 50\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y135sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 3. cuda out of memory error (fixed)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y135sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m resnet18 \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49mresnet18()\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y135sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y135sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   out \u001b[39m=\u001b[39m resnet18(d\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\cuda\\__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# 3. cuda out of memory error (fixed)\n",
    "resnet18 = models.resnet18().to(\"cuda:0\")\n",
    "for d in data:\n",
    "  out = resnet18(d.to(\"cuda:0\").unsqueeze(0))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\xdxd2\\Sunny_VS_worksapce\\Sunny_python\\lee hung yi\\ML2021-Spring\\Pytorch\\01_Pytorch_Tutorial.ipynb Cell 51\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y136sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m outs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y136sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m0\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/xdxd2/Sunny_VS_worksapce/Sunny_python/lee%20hung%20yi/ML2021-Spring/Pytorch/01_Pytorch_Tutorial.ipynb#Y136sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m lossval \u001b[39m=\u001b[39m L(outs,labels)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "# 4. mismatched tensor type\n",
    "import torch.nn as nn\n",
    "L = nn.CrossEntropyLoss()\n",
    "outs = torch.randn(5,5)\n",
    "labels = torch.Tensor([1,2,3,4,0])\n",
    "lossval = L(outs,labels) # Calculate CrossEntropyLoss between outs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3373)\n"
     ]
    }
   ],
   "source": [
    "# 4. mismatched tensor type (fixed)\n",
    "labels = labels.long()\n",
    "lossval = L(outs,labels)\n",
    "print(lossval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
