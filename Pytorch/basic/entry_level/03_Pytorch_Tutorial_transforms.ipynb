{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "# import tensorflow as tf\n",
        "from PIL import Image\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# python的用法 -> tensor 數據類型\n",
        "# 通過 transforms.ToTensor 去看兩個問題\n",
        "# 1. transforms 被如何使用 (python)\n",
        "# 2. 為甚麼我們需要 Tensor 數據類型\n",
        "\n",
        "\n",
        "# 常見的 Transforms \n",
        "# 1. 輸入 *PIL -> Image.open()\n",
        "# 2. 輸出 *tensor -> ToTensor\n",
        "# 3. 作用 *narrays -> cv.imread()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 絕對路徑\n",
        "img_path_abs = r\"C:\\Users\\xdxd2\\Sunny_VS_worksapce\\Sunny_python\\lee hung yi\\ML2021-Spring\\Pytorch\\hymenoptera_data\\train\\ants\\6240329_72c01e663e.jpg\"\n",
        "# 相對路徑\n",
        "img_path = r\".\\hymenoptera_data\\train\\ants\\45472593_bfd624f8dc.jpg\"\n",
        "\n",
        "img = Image.open(img_path)\n",
        "tensor_trans = transforms.ToTensor()\n",
        "tensor_img = tensor_trans(img)\n",
        "# print(img)\n",
        "# print(tensor_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 333, 500])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "cv_img = cv2.imread(img_path)\n",
        "writer = SummaryWriter(\"logs_\")\n",
        "\n",
        "#1 transforms 這如何使用 (python)\n",
        "tensor_trans = transforms.ToTensor()\n",
        "tensor_img = tensor_trans(img)\n",
        "\n",
        "writer.add_image(\"Tensor_img\", tensor_img)\n",
        "writer.close()\n",
        "\n",
        "# tensorboard --logsir=logs --port=6007\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## call function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "__call__: hello leo\n",
            "hello leo\n"
          ]
        }
      ],
      "source": [
        "class Person:\n",
        "    def __call__(self, name):\n",
        "        print(\"__call__: \" + \"hello \" + name)\n",
        "    \n",
        "    def hello(self, name):\n",
        "        print(\"hello \" + name)\n",
        "\n",
        "person = Person()\n",
        "person(\"leo\")\n",
        "person.hello(\"leo\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ToTensor && Normalize && Resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms\n",
        "from datetime import datetime\n",
        "import os\n",
        "import shutil\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## subdirectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# subdirectory\n",
        "now = datetime.now()\n",
        "logdir = \"pytorch_logs/\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "\n",
        "# Check if the directoryexists\n",
        "if os.path.exists(logdir):\n",
        "    # Delete the directory and all its contents\n",
        "    shutil.rmtree(logdir)\n",
        "\n",
        "# recreate the directory if plan to continue logging\n",
        "os.makedirs(logdir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## summary writter\n",
        "### 資料紀錄器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x333 at 0x18911DD01F0>\n"
          ]
        }
      ],
      "source": [
        "writter = SummaryWriter(logdir)\n",
        "# writter.flush()\n",
        "img = Image.open(img_path)\n",
        "print(img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ToTensor\n",
        "### tensor 轉換器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ToTensor\n",
        "trans_totensor = transforms.ToTensor()\n",
        "img_tensor = trans_totensor(img)\n",
        "writter.add_image(\"ToTensor\", img_tensor, 0)\n",
        "\n",
        "writter.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.9686, 0.9216, 0.9059,  ..., 0.9216, 0.8667, 0.9686],\n",
            "        [0.8667, 0.3647, 0.3176,  ..., 0.0353, 0.1059, 0.8588],\n",
            "        [0.9922, 0.2863, 0.3961,  ..., 0.1922, 0.1373, 0.9294],\n",
            "        ...,\n",
            "        [0.9843, 0.4510, 0.4118,  ..., 0.2471, 0.2549, 0.9843],\n",
            "        [0.9059, 0.3098, 0.2392,  ..., 0.1137, 0.1686, 0.8745],\n",
            "        [0.9608, 0.8431, 0.9373,  ..., 0.9686, 0.8824, 0.9843]])\n"
          ]
        }
      ],
      "source": [
        "# Normalize\n",
        "trans_norm = transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
        "img_norm = trans_norm(img_tensor)\n",
        "print(img_norm[0])\n",
        "writter.add_image(\"Normalize\", img_norm, 1)\n",
        "\n",
        "writter.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before resize (500, 333)\n",
            "after resize torch.Size([3, 512, 512])\n"
          ]
        }
      ],
      "source": [
        "# resize\n",
        "print(\"before resize\", img.size)\n",
        "# img PIL -> resize -> img_resize PIL\n",
        "trans_resize = transforms.Resize((512,512))\n",
        "img_resize = trans_resize(img)\n",
        "# img_resize PIL -> totensor -> img_resize tensor\n",
        "img_resize = trans_totensor(img_resize)\n",
        "print(\"after resize\",img_resize.shape)\n",
        "writter.add_image(\"Resize\", img_resize, 2)\n",
        "\n",
        "writter.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compose - resize -2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compose - resize -2\n",
        "trans_resize_2 = transforms.Resize(512)\n",
        "# PIL -> PIL -> tensor\n",
        "trans_compose = transforms.Compose([trans_resize_2, trans_totensor])\n",
        "img_resize_2 = trans_compose(img)\n",
        "writter.add_image(\"Resize-2\", img_resize_2, 3)\n",
        "\n",
        "writter.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomCorp\n",
        "### 隨機裁切"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "trans_random = transforms.RandomCrop(512)\n",
        "trans_compose_2 = transforms.Compose([trans_resize_2, trans_random, trans_totensor])\n",
        "\n",
        "for i in range(10):\n",
        "    img_crop = trans_compose_2(img)\n",
        "    writter.add_image(\"RandomCrop\", img_crop, i)\n",
        "\n",
        "writter.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Pytorch Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
