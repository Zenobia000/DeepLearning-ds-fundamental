{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "image_path = r\"C:\\Users\\xdxd2\\Sunny_VS_worksapce\\Sunny_python\\lee hung yi\\ML2021-Spring\\Pytorch\\dog_cat_data\\dataset\\training_set\\cats\\cat.3981.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=336x335 at 0x25AFA498160>\n"
          ]
        }
      ],
      "source": [
        "image = Image.open(image_path)\n",
        "print(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((32,32)),\n",
        "    torchvision.transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "image = transform(image)\n",
        "print(image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "class nn_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(nn_model, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 5, 1, 2),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 32, 5, 1, 2),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 5, 1, 2),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*4*4, 64),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "    \n",
        "nn_model = nn_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn_model.load_state_dict(torch.load(\"nn_model_CIFAR10_0_state_dict.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nn_model(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    (7): Linear(in_features=1024, out_features=64, bias=True)\n",
            "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "tensor([[-1.8682, -0.2810, -0.9845,  1.5303, -0.6581,  1.2543,  1.2927,  0.6778,\n",
            "         -1.2781,  0.9700]])\n",
            "tensor([3])\n"
          ]
        }
      ],
      "source": [
        "# model = torch.load(\"nn_mode_CIFAR10_0.pth\", map_location=torch.device('cpu'))\n",
        "print(nn_model)\n",
        "\n",
        "image = torch.reshape(image, (1,3,32,32))\n",
        "\n",
        "nn_model.eval()\n",
        "with torch.no_grad():\n",
        "    output = nn_model(image)\n",
        "\n",
        "print(output)\n",
        "print(output.argmax(1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Pytorch Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
