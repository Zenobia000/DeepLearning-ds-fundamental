{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = white size=6 >如何將資料丟到CUDA。</font>**\n",
    "\n",
    "\n",
    "在torch的tensor下直接.to(device)即可，但device需要先宣告。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認GPU數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "tensor([5, 0])\n",
      "tensor([5, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "transform = transforms.ToTensor()\n",
    "dataset_MNIST_tensor = datasets.MNIST('../data/cv', train=True, download=True, transform=transform)\n",
    "mnistdata_loader = torch.utils.data.DataLoader(dataset_MNIST_tensor, batch_size=2)\n",
    "\n",
    "\n",
    "use_cuda = 1\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() & use_cuda) else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "for data, target in mnistdata_loader:\n",
    "    print(target)\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我們針對CPU mode的tensor和CUDA mode的tensor做操作看看\n",
    "\n",
    "### 1. CPU Tensor 相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "use_cuda = 0\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "one = torch.Tensor([1])\n",
    "for data, target in mnistdata_loader:\n",
    "    print(data+one)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CUDA Tensor 加 CPU Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "one = torch.Tensor([1])\n",
    "for data, target in mnistdata_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    print(data)\n",
    "    print(data+one)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. CUDA Tensor 加 CUDA Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "use_cuda = 1\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "one = torch.Tensor([1])\n",
    "one = one.to(device)\n",
    "for data, target in mnistdata_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    print(data+one)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 測試CPU和CUDA之間資料搬移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When batch size = 10\n",
      "a forloop time for whole dataset within CPU: 2.253023862838745s\n",
      "a forloop time for whole dataset with CPU to CUDA: 4.19034218788147s\n",
      "\n",
      "When batch size = 2\n",
      "a forloop time for whole dataset within CPU: 2.874025583267212s\n",
      "a forloop time for whole dataset with CPU to CUDA: 8.376002311706543s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def test_time(data_loader):\n",
    "    start = time.time()\n",
    "    count=0\n",
    "    for data, target in data_loader:\n",
    "        count+=1\n",
    "    print(\"a forloop time for whole dataset within CPU: {}s\".format(time.time()-start))\n",
    "\n",
    "    start = time.time()\n",
    "    count=0\n",
    "    for data, target in data_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        count+=1\n",
    "    print(\"a forloop time for whole dataset with CPU to CUDA: {}s\".format(time.time()-start))\n",
    "    \n",
    "print(\"When batch size = 10\")\n",
    "mnistdata_loader = torch.utils.data.DataLoader(dataset_MNIST_tensor, batch_size=10, shuffle=False)\n",
    "test_time(mnistdata_loader)\n",
    "\n",
    "print(\"\\nWhen batch size = 2\")\n",
    "mnistdata_loader = torch.utils.data.DataLoader(dataset_MNIST_tensor, batch_size=2, shuffle=False)\n",
    "test_time(mnistdata_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</font>**<font color = black size=4 >Note: </font>**<br>\n",
    "\n",
    "**<font color = black size=3 >1:資料跑來跑去一定花費data bandwidth，導致時間會變慢，所以在pytorch撰寫過程中要盡量避免資料在CPU和GPU之間跑來跑去。</font>**<br>\n",
    "\n",
    "**<font color = black size=3 >2: 容易造成CPU的tensor和CUDA的tensor進行運算的error，在進行運算要注意是在CPU還是CUDA。</font>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
