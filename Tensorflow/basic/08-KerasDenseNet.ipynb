{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用DenseNet做模型訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本練習使用CIFAR10資料集：https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from densenet import MY_DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='01'>載入圖片至電腦記憶體 </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先看一下包含資料集的資料夾有什麼內容："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -hl ../datasets/cifar-10-batches-py/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_batch_1, data_batch_2,..data_batch_5以及test_batch是以binary的方式儲存在硬碟裡。以下我們寫幾個函數，用以載入這些binary格式的圖檔至電腦內的記憶體中，並且將圖的以矩陣的方式儲存。這些圖矩陣的shape為(Number of figures,Width,Height,Channel)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(fpath):\n",
    "    \"\"\"This function extract a batch of CIFAR10 data\n",
    "       from the chosen binary file.\n",
    "       This function is a simplified version of\n",
    "       https://github.com/keras-team/keras/blob/master/keras/datasets/cifar.py\n",
    "    \"\"\"\n",
    "    with open(fpath, 'rb') as f:\n",
    "        d = pickle.load(f, encoding='bytes')\n",
    "        # Keys are in the \"byte\" format. Let's decode them into utf8 strings.\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode('utf8')] = v\n",
    "        d = d_decoded\n",
    "    data = d['data']\n",
    "    labels = d['labels']\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    data = data.transpose(0,2,3,1)\n",
    "    return data,labels\n",
    "\n",
    "def load_data(path):\n",
    "    '''\n",
    "    載入以binary方式儲存的影像至電腦內記憶體。\n",
    "    '''\n",
    "    num_train_samples = 50000\n",
    "\n",
    "    x_train = np.zeros((num_train_samples, 32,32,3), dtype='uint8')\n",
    "    y_train = np.zeros((num_train_samples,), dtype='uint8')\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        fpath = os.path.join(path, 'data_batch_') + str(i)\n",
    "        data, labels = load_batch(fpath)\n",
    "        x_train[(i - 1) * 10000:i * 10000, :, :, :] = data\n",
    "        y_train[(i - 1) * 10000:i * 10000] = labels\n",
    "\n",
    "    fpath = os.path.join(path, 'test_batch')\n",
    "    x_test, y_test = load_batch(fpath)\n",
    "\n",
    "    return (x_train, y_train), (np.array(x_test), np.array(y_test,dtype=\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data('../datasets/cifar-10-batches-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上，我們得到了x_train, x_test, y_train,y_test四個放置圖片的矩陣，其shape均為(Number of figures,Width,Height,Channel)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們抽出幾張圖來看，稍微了解一下這些資料大概的樣貌："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/cifar-10-batches-py/labels.txt\") as reader:\n",
    "    fig_labels = reader.read()\n",
    "fig_labels = fig_labels.split(\"\\n\")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_label = {}\n",
    "for idx,fig_labels in enumerate(fig_labels):\n",
    "        idx_to_label[idx] = fig_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#隨機抽取12張圖來看一下\n",
    "num_figures_display = 12\n",
    "fig_indexes = np.random.choice(x_train.shape[0],num_figures_display)\n",
    "\n",
    "fig,axes = plt.subplots(2,6)\n",
    "for fig_idx, axis in zip(fig_indexes, axes.reshape(-1) ):\n",
    "    axis.axis('off')\n",
    "    axis.imshow(x_train[fig_idx])\n",
    "    axis.set_title(idx_to_label[ y_train[fig_idx] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#%E6%9C%AC%E7%AD%86%E8%A8%98%E7%9A%84%E5%85%A7%E5%AE%B9%E5%A6%82%E4%B8%8B%EF%BC%9A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='02'> 將圖片做一些預處理 </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做normalization\n",
    "data_type=np.float32\n",
    "n_channels=3\n",
    "for i in range(n_channels):\n",
    "    mean = np.mean(x_train[:, :, :, i])\n",
    "    std = np.std(x_train[:, :, :, i])\n",
    "    x_train[:, :, :, i] = ( (x_train[:, :, :, i] - mean) / std ).astype(data_type)\n",
    "    x_test[:, :, :, i] =  ( (x_test[:, :, :, i] - mean) / std ).astype(data_type)\n",
    "# 模型只看過train data, 故只能用train data來計算mean, std。 做資料驗證時，test data也需要用相同的mean, std來將其轉換。\n",
    "    \n",
    "# # 另一個簡單的normalization方式，是將x直接除以255，使得x內的所有值均分佈於[0,1]之間。\n",
    "# x_train=(x_train/255. ).astype(data_type)\n",
    "# x_test=(x_test/255. ).astype(data_type)\n",
    "\n",
    "# 將y轉換成為one hot的形式\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10).astype(data_type)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10).astype(data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#%E6%9C%AC%E7%AD%86%E8%A8%98%E7%9A%84%E5%85%A7%E5%AE%B9%E5%A6%82%E4%B8%8B%EF%BC%9A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='03'> 建立並訓練模型 </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= 模型訓練參數設定 =======\n",
    "num_epochs=275\n",
    "batch_size=64\n",
    "weight_decay=1.E-4\n",
    "learning_rate=0.1\n",
    "# ==============================\n",
    "\n",
    "# ========= 排程參數設定 =========\n",
    "def schedule(epoch):\n",
    "    if 150 <= epoch < 225:\n",
    "        lr=0.01\n",
    "    elif epoch >= 225:\n",
    "        lr=0.001\n",
    "    else:\n",
    "        lr=0.1\n",
    "    return lr\n",
    "\n",
    "model_save_path='../models/cifar10-densenet100-sgd-{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_save_interval=100\n",
    "# ==============================\n",
    "\n",
    "# 設定訓練途中存擋，以及更改learning rate\n",
    "lr_decay_scheduler = LearningRateScheduler(schedule)\n",
    "earlyStopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "checkPointer = ModelCheckpoint(model_save_path, \n",
    "                               monitor='val_loss', \n",
    "                               verbose=1,\n",
    "                               save_best_only=False,\n",
    "                               save_weights_only=False,\n",
    "                               mode='auto', \n",
    "                               period=model_save_interval)\n",
    "# 取得模型\n",
    "model=MY_DenseNet(in_shape=(32,32,3),\n",
    "                  out_classes=10,\n",
    "                  weight_decay=weight_decay).build_model()\n",
    "# 定義模型優化方式\n",
    "opt=SGD(lr=learning_rate,\n",
    "        momentum=0.9,\n",
    "        nesterov=True,\n",
    "        decay=0.)\n",
    "# 編譯模型：給定模型目標和訓練方式\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "# 訓練模型\n",
    "history=model.fit(x_train,y_train_one_hot,\n",
    "                  epochs=num_epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  validation_split=0.1,\n",
    "                  callbacks=[lr_decay_scheduler,\n",
    "                             earlyStopper,\n",
    "                             checkPointer])\n",
    "#畫出訓練過程\n",
    "fig,axes=plt.subplots(1,2,figsize=(18,6))\n",
    "axes[0].plot(model.history.history['acc'], ms=5, marker='o', label='train acc',ls='--')\n",
    "axes[0].plot(model.history.history['val_acc'], ms=5, marker='o', label='val acc',ls='--')\n",
    "axes[0].legend()\n",
    "axes[1].plot(model.history.history['loss'], ms=5, marker='o', label='train loss',ls='--')\n",
    "axes[1].plot(model.history.history['val_loss'], ms=5, marker='o', label='val loss',ls='--')\n",
    "axes[1].legend()\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[回索引](#%E6%9C%AC%E7%AD%86%E8%A8%98%E7%9A%84%E5%85%A7%E5%AE%B9%E5%A6%82%E4%B8%8B%EF%BC%9A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_save_path='../models/cifar10-densenet100-sgd-epoch-final.hdf5'\n",
    "# model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
