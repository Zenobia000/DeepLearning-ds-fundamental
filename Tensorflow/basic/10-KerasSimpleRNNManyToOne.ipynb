{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 此筆記介紹 many to one這個種類的 RNN。\n",
    "\n",
    "所謂many to one即：於多個(many)連續的時間點讀取資訊(例如：$\\vec{x}_{t=0},\\vec{x}_{t=1},\\vec{x}_{t=2}$)，然後來預測接下來單一(one)個時間點的資訊 ($\\vec{x}_{t=3}$)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: 使用SimpleRNN學習 $[1,0,0,1,0,0,1,0,0,1,0,0,1,....]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們接下來會利用 $x_{t=0},x_{t=1},x_{t=2}$ 來預測 $x_{t=3}$。\n",
    "\n",
    "### 1.1. 先產生用於訓練和測試的資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 200 # 建立兩百個序列樣本\n",
    "num_train = 150   # 其中150個當訓練資料，50個用於測試模型好壞\n",
    "\n",
    "fake_data = np.array([[0,1,0,0],[1,0,0,1],[0,0,1,0]]) # 每個樣本含四個連續時間：前三個時間的資料會讓網路讀取，後一個時間的資料\n",
    "                                                    # 是網路的預測目標。\n",
    "data = np.zeros((num_samples,4),dtype=np.float32 )\n",
    "for j in range(num_samples):\n",
    "    rand_idx = np.random.choice(3)\n",
    "    rand_data = fake_data[rand_idx]\n",
    "    data[j,:] = rand_data\n",
    "    \n",
    "train_x = data[0:num_train,0:3]\n",
    "test_x = data[num_train:num_samples,0:3]\n",
    "train_y = data[0:num_train,3].astype(np.int8)\n",
    "test_y = data[num_train:num_samples,3].astype(np.int8)\n",
    "print(train_y.shape, train_x.shape, test_y.shape, test_x.shape)\n",
    "\n",
    "train_x = train_x.reshape((*train_x.shape,1))\n",
    "test_x = test_x.reshape((*test_x.shape,1))\n",
    "print(train_y.shape, train_x.shape, test_y.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. 建立並訓練模型，將模型的訓練情形畫出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = 30\n",
    "\n",
    "time_dim = 3\n",
    "seq_dim = 1\n",
    "\n",
    "# 建立模型(將SimpleRNN與Dense層依序添加至模型內)。\n",
    "model = Sequential()  \n",
    "model.add(SimpleRNN(input_shape=(time_dim,seq_dim),\n",
    "                    units=hidden_neurons,\n",
    "                    return_sequences=False))  \n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "                    epochs=100, batch_size=32, validation_split=0.3)  # 訓練模型。\n",
    "\n",
    "# 畫出模型訓練情形。\n",
    "plt.plot(history.history['acc'], ms=5, marker='o', label='accuracy')\n",
    "plt.plot(history.history['val_acc'], ms=5, marker='o', label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. 丟3個樣本進去做預測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred=np.array([[0,1,0],[0,0,1],[1,0,0]]).reshape((3,3,1))\n",
    "\n",
    "#print( model.predict(x_pred) )\n",
    "#print()\n",
    "print(\"predictions=\", pd.Series(model.predict(x_pred)[:,0]).apply(lambda x:1 if x>0.5 else 0) \\\n",
    "                                     .values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這三個樣本事實上機器都看過，故應該會預測的很完美。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2. 輸入時間序列： $x_{t=1},x_{t=2},...,x_{t=n}$，預測 $\\vec{x}_{t=n+1}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 建立訓練用序列資料：$sin(\\pi x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,np.pi,100)\n",
    "y = np.sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從$sin(x)$序列中抽取$x_{t=1},x_{t=2},...,x_{t=25}$。其中，$x_{t=1},x_{t=2},...,x_{t=20}$將於不同的時間點丟入模型，最後，模型會預測出單一向量$\\vec{y} = (x_{t=21},x_{t=22},x_{t=23},...,x_{t=25}$)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20 # 有20個連續的時間點。於每個時間點我們都會輸入資料給模型。\n",
    "m = 5  # 模型將預測的向量維度是5。\n",
    "num_samples = 300 # 300個訓練樣本。\n",
    "\n",
    "train_x = np.zeros((num_samples,n),dtype=np.float32 )\n",
    "train_y = np.zeros((num_samples,m),dtype=np.float32 )\n",
    "\n",
    "for j in range(num_samples):\n",
    "    rand_num = np.random.choice(100-(n+m))\n",
    "    train_x[j,:] = y[rand_num:rand_num+n]\n",
    "    train_y[j,:] = y[rand_num+n:rand_num+n+m]\n",
    "    \n",
    "plt.scatter(x=np.arange(20), y=train_x[8,:], label=\"train_x\")\n",
    "plt.scatter(x=np.arange(20,25), y=train_y[8,:], label=\"train_y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸入給RNN的資料需要是3D，故我們在這裡轉換```train_x```的shape。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_x.reshape(*train_x.shape,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. 建立並訓練模型，且畫出模型訓練情形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = 15\n",
    "\n",
    "time_dim = 20\n",
    "seq_dim = 1\n",
    "\n",
    "model = Sequential()  \n",
    "model.add(SimpleRNN(input_shape=(time_dim,seq_dim),\n",
    "                    units=hidden_neurons,\n",
    "                    return_sequences=False))  \n",
    "model.add(Dense(5,activation='tanh'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(train_x, train_y,\n",
    "                  epochs=200, batch_size=32, validation_split=0.3)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.plot(history.history['mean_squared_error'], ms=5, marker='o', label='mse')\n",
    "plt.plot(history.history['val_mean_squared_error'], ms=5, marker='o', label='val mse')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. 丟一個隨機樣本進去做預測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_num=np.random.choice(100-(n+m))\n",
    "test_x=y[rand_num:rand_num+n]\n",
    "test_y=y[rand_num+n:rand_num+n+m]\n",
    "\n",
    "y_pred=model.predict( test_x.reshape(1,20,1) )\n",
    "\n",
    "plt.scatter(x=np.arange(20), y=test_x, label=\"x\")\n",
    "plt.scatter(x=np.arange(20,25), y=test_y, label=\"y\")\n",
    "plt.scatter(x=np.arange(20,25), y=y_pred, label=\"pred_y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般來說，我們不會拿時序資料來預測一個含有時序資訊的向量($\\vec{x}_{t=n+1}$)。因為，該時序向量內的資訊可能也有時間上的關聯性。該向量的末端元素可能和該向量內的前端元素比較無關連，卻和前一個元素有極大關聯性。在這個模型下，時序向量內元素間的關聯性將被忽略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3. 輸入時間序列： $x_{t=1},x_{t=2},...,x_{t=n}$，預測 $x_{t=n+1}$。\n",
    "\n",
    "記得剛才Case1的序列，其週期為3。以下我們來嘗試週期為15的序列："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. 建立訓練用序列資料：$\\cos(2\\pi b j +\\phi)$, where $b=\\frac{1}{15}$, $j=0,1,2,...,299$ and $\\phi=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(300)\n",
    "phi = 0\n",
    "b = 1./15.\n",
    "y = np.cos(2.*np.pi*b*x+phi)\n",
    "\n",
    "n = 20\n",
    "m = 1\n",
    "num_samples = 300\n",
    "\n",
    "train_x = np.zeros((num_samples,n), dtype=np.float32 )\n",
    "train_y = np.zeros((num_samples,m), dtype=np.float32 )\n",
    "\n",
    "for j in range(num_samples):\n",
    "    rand_num = np.random.choice(100-(n+m))\n",
    "    train_x[j,:] = y[rand_num:rand_num+n]\n",
    "    train_y[j,:] = y[rand_num+n:rand_num+n+m]\n",
    "\n",
    "rand_choice = 8\n",
    "plt.scatter(x=np.arange(20), y=train_x[rand_choice,:], label=\"train_x\")\n",
    "plt.scatter(x=np.arange(20,21), y=train_y[rand_choice,:], label=\"train_y\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "train_x = train_x.reshape(*train_x.shape,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. 建立並訓練模型，且畫出模型訓練情形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = 15\n",
    "\n",
    "time_dim = 20\n",
    "seq_dim = 1\n",
    "\n",
    "model = Sequential()  \n",
    "model.add(SimpleRNN(input_shape=(time_dim,seq_dim),\n",
    "                    units=hidden_neurons,\n",
    "                    return_sequences=False))  \n",
    "model.add(Dense(1,activation='tanh'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['mse'])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(train_x, train_y,\n",
    "                  epochs=200, batch_size=32, validation_split=0.3)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.plot(history.history['mean_squared_error'], ms=5, marker='o', label='mse')\n",
    "plt.plot(history.history['val_mean_squared_error'], ms=5, marker='o', label='val mse')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. 丟入64個隨機樣本進去做預測。抽看其中一個樣本的預測結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(300)\n",
    "phi = np.pi/3.\n",
    "b = 1./15.\n",
    "y = np.cos(2.*np.pi*b*x+phi)\n",
    "\n",
    "\n",
    "test_samples = 64\n",
    "\n",
    "tests_x = np.zeros( (test_samples,n)  )\n",
    "tests_y = np.zeros( (test_samples,1)  )\n",
    "\n",
    "rand_nums = np.zeros(test_samples)\n",
    "for j in range(test_samples):\n",
    "    rand_num = np.random.choice(300-(n+m))\n",
    "    tests_x[j,:] = y[rand_num:rand_num+n]\n",
    "    tests_y[j,:] = y[rand_num+n:rand_num+n+m]\n",
    "    rand_nums[j] = rand_num\n",
    "    \n",
    "tests_x = tests_x.reshape(test_samples,20,1)\n",
    "y_pred = model.predict( tests_x )\n",
    "\n",
    "choice_idx = 5\n",
    "\n",
    "plt.scatter(x=np.arange(rand_nums[choice_idx], rand_nums[choice_idx]+n), y=tests_x[choice_idx],label=\"x\")\n",
    "plt.scatter(x=np.arange(rand_nums[choice_idx]+n, rand_nums[choice_idx]+n+m), y=tests_y[choice_idx],label=\"y\")\n",
    "plt.scatter(x=np.arange(rand_nums[choice_idx]+n, rand_nums[choice_idx]+n+m), y=y_pred[choice_idx],label=\"pred_y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. 看數個預測結果是否貼合真實資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_xy = np.zeros((2,m*test_samples))\n",
    "\n",
    "for j in range(test_samples):\n",
    "    pred_y_xy[0,m*j:m*(j+1)] = np.arange(rand_nums[j]+n, rand_nums[j]+n+m)\n",
    "    pred_y_xy[1,m*j:m*(j+1)] = y_pred[j].T\n",
    "    \n",
    "plt.scatter(x,y)\n",
    "\n",
    "plt.scatter(x=pred_y_xy[0,:], y=pred_y_xy[1,:])\n",
    "plt.xlim((0,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 4. 輸入時間序列： $x_{t=1},x_{t=2},...,x_{t=n}$，預測 $x_{t=n+1}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下我們來嘗試一個週期為無限大，卻彷彿有週期的序列："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. 建立訓練用序列資料：$\\cos(2\\pi b j +\\phi)$, where $b=\\frac{1+\\sqrt{5}}{2}$, $j=0,1,2,...,299$ and $\\phi=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立該序列\n",
    "x = np.arange(1000)\n",
    "phi = 0.\n",
    "b = (1.+np.sqrt(5.))/2.\n",
    "y = np.cos(2.*np.pi*b*x+phi)\n",
    "\n",
    "# 決定如何建立訓練資料\n",
    "n = 20            # 訓練資料共20個時間點\n",
    "m = 1             # 我們要來預測第21個時間點的資訊應為何。第21個時間點的向量維度應為1。\n",
    "num_samples = 500 # 訓練資料五百筆\n",
    "\n",
    "# 製作訓練資料\n",
    "train_x = np.zeros((num_samples,n),dtype=np.float32 )\n",
    "train_y = np.zeros((num_samples,m),dtype=np.float32 )\n",
    "for j in range(num_samples):\n",
    "    rand_num = np.random.choice(100-(n+m))\n",
    "    train_x[j,:] = y[rand_num:rand_num+n]\n",
    "    train_y[j,:] = y[rand_num+n:rand_num+n+m]\n",
    "\n",
    "# 抽一個訓練用的樣本畫出來看看\n",
    "rand_choice = 8\n",
    "plt.plot(np.arange(n), train_x[rand_choice,:],\n",
    "         ms=7,marker='o',label=\"train_x\")\n",
    "plt.scatter(x=np.arange(n,n+1), y=train_y[rand_choice,:],\n",
    "            label=\"train_y\", color='green')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# train_x需轉為3D，方能做為SimpleRNN層的輸入\n",
    "train_x = train_x.reshape(*train_x.shape,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將局部的$\\cos(2\\pi b j +\\phi)$序列畫出來看一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y,ms=7,marker='o')\n",
    "plt.xlim(0,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. 建立並訓練模型，且畫出模型訓練情形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = 50\n",
    "\n",
    "time_dim = 20\n",
    "seq_dim = 1\n",
    "\n",
    "model = Sequential()  \n",
    "model.add(SimpleRNN(input_shape=(time_dim,seq_dim), \n",
    "                    units=hidden_neurons,\n",
    "                    return_sequences=False))  \n",
    "model.add(Dense(1, activation='tanh'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mse'])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(train_x, train_y,\n",
    "                  epochs=200, batch_size=64, validation_split=0.2)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.plot(history.history['mean_squared_error'], ms=5,marker='o', label='mse')\n",
    "plt.plot(history.history['val_mean_squared_error'], ms=5,marker='o', label='val mse')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. 丟一個隨機樣本進去做預測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1000)\n",
    "phi = 0.123 * np.pi\n",
    "b = (1. + np.sqrt(5.)) / 2.\n",
    "y = np.cos(2. * np.pi * b * x + phi)\n",
    "\n",
    "test_samples = 64\n",
    "\n",
    "tests_x = np.zeros((test_samples,n))\n",
    "tests_y = np.zeros((test_samples,1))\n",
    "\n",
    "rand_nums = np.zeros(test_samples)\n",
    "for j in range(test_samples):\n",
    "    rand_num = np.random.choice(300-(n+m))\n",
    "    tests_x[j,:] = y[rand_num:rand_num+n]\n",
    "    tests_y[j,:] = y[rand_num+n:rand_num+n+m]\n",
    "    rand_nums[j] = rand_num\n",
    "\n",
    "tests_x = tests_x.reshape(test_samples, 20, 1)\n",
    "y_pred = model.predict(tests_x)\n",
    "\n",
    "choice_idx = 5\n",
    "plt.scatter(x=np.arange(rand_nums[choice_idx], rand_nums[choice_idx]+n), y=tests_x[choice_idx], label=\"x\")\n",
    "plt.scatter(x=np.arange(rand_nums[choice_idx]+n, rand_nums[choice_idx]+n+m), y=tests_y[choice_idx], label=\"y\")\n",
    "plt.scatter(x=np.arange(rand_nums[choice_idx]+n, rand_nums[choice_idx]+n+m), y=y_pred[choice_idx], label=\"pred_y\")\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雖然資料可能不具有週期性，但，只要資料彷彿有某種規律，機器就可以學習那個規律。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
